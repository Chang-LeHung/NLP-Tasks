{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type Token Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import plotly.graph_objs as go\n",
    "import random\n",
    "\n",
    "\n",
    "class TTRCompare(object):\n",
    "    \"\"\"\n",
    "    Usage Example:\n",
    "    ```\n",
    "    ttrs_obj = TTRCompare(\"Pubmed.txt\", \"Brow Corpus.txt\", repeat=15)\n",
    "    ttrs_obj.shape()\n",
    "    ttrs_obj.visual()\n",
    "    ttrs_obj.ttrs_detail()\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(self, path1, path2, repeat=1, encoding=\"utf-8\", max_words_num=40000):\n",
    "        self._path1 = path1\n",
    "        self._path2 = path2\n",
    "        self.repeat = repeat\n",
    "        self.nums1 = None\n",
    "        self.nums2 = None\n",
    "        self.max_length = 0\n",
    "        self.ttrs1 = None\n",
    "        self.ttrs2 = None\n",
    "        self.words1 = None\n",
    "        self.words2 = None\n",
    "        self.encoding = encoding\n",
    "        self.max_words_num = max_words_num\n",
    "\n",
    "    def shape(self):\n",
    "        self.words1 = self._load_data(self._path1)\n",
    "        self.words2 = self._load_data(self._path2)\n",
    "        self.max_length = min(len(self.words1), len(self.words2), self.max_words_num)\n",
    "        self.nums1, self.ttrs1 = self.find_ttr_continuous(self.words1, repeat=self.repeat)\n",
    "        self.nums2, self.ttrs2 = self.find_ttr_continuous(self.words2, repeat=self.repeat)\n",
    "\n",
    "    def _words_count(self, word_sequence: list) -> list:\n",
    "        \"\"\"\n",
    "        统计每个单词数出现的字数\n",
    "        返回单词和其出现的次数\n",
    "        return example : [(\"apple\", 5)]\n",
    "        \"\"\"\n",
    "        words = dict()\n",
    "        for word in word_sequence:\n",
    "            if word == \"\":\n",
    "                continue\n",
    "            words[word] = words.get(word, 0) + 1\n",
    "        return list(words.items())\n",
    "\n",
    "    def _load_data(self, path):\n",
    "        \"\"\"\n",
    "        通过路径加载数据\n",
    "        return example : [\"apple\", \"banana\", \"apple\"]\n",
    "        \"\"\"\n",
    "        with open(path, \"r+\", encoding=self.encoding) as fp:\n",
    "            data = re.split(r\"[ \\'\\\"(){}!-=/@#$%^&*~?\\n_.]\", fp.read())\n",
    "            ans = []\n",
    "            for char in data:\n",
    "                if not char == \"\":\n",
    "                    ans.append(char)\n",
    "            return ans\n",
    "\n",
    "    def _random_choice(self, words: list, num: int) -> list:\n",
    "        \"\"\"\n",
    "        从words中随机抽取num个单词\n",
    "        \"\"\"\n",
    "        if num > len(words):\n",
    "            raise ValueError(\"num is bigger than length of words list\")\n",
    "        return random.choices(words, k=num)\n",
    "\n",
    "    def find_ttr_continuous(self, word_count, repeat=10):\n",
    "        \"\"\"\n",
    "        从word_count抽取k个单词重复计算repeat词，去ttr的平均值\n",
    "        k = 1, 2, 3, ..., len(word_count)\n",
    "        \"\"\"\n",
    "        nums = [i for i in range(1, self.max_length)]\n",
    "        ttrs = []\n",
    "        for num in nums:\n",
    "            ttr = 0\n",
    "            for i in range(repeat):\n",
    "                ttr += self.calculate_ttr(self._words_count(self._random_choice(word_count,\n",
    "                                                                              num)))\n",
    "            ttrs.append(ttr / repeat)\n",
    "        return nums, ttrs\n",
    "\n",
    "    def visual(self):\n",
    "        \"\"\"\n",
    "        可视化ttr随单词数目变化情况\n",
    "        \"\"\"\n",
    "        fig = go.Figure([go.Scatter(x=self.nums1, y=self.ttrs1, name=\"Average\" + self._path1.split(r\".\")[0]),\n",
    "                         go.Scatter(x=self.nums1, y=[sum(self.ttrs1) / len(self.ttrs1)] * len(self.nums1)\n",
    "                                    , name=\"Average\" + self._path1.split(r\".\")[0]),\n",
    "                         go.Scatter(x=self.nums1, y=self.ttrs2, name=\"Average\" + self._path2.split(r\".\")[0]),\n",
    "                         go.Scatter(x=self.nums1, y=[sum(self.ttrs2) / len(self.ttrs2)] * len(self.nums1)\n",
    "                                    , name=\"Average\" + self._path2.split(r\".\")[0])])\n",
    "        fig.update_layout(xaxis_title=\"words_num\", yaxis_title=\"ttr\",\n",
    "                          title=\"ttr随单词数目变化情况\")\n",
    "        fig.show()\n",
    "\n",
    "    def calculate_ttr(self, words):\n",
    "        return len(words) / sum([item[1] for item in words])\n",
    "\n",
    "    def ttrs_detail(self):\n",
    "        return {\n",
    "            \"path1_detail\": self.ttrs1,\n",
    "            \"path1_average\": sum(self.ttrs1) / len(self.ttrs1),\n",
    "            \"path2_detail\": self.ttrs2,\n",
    "            \"path2_average\": sum(self.ttrs2) / len(self.ttrs2),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ttrs_obj = TTRCompare(\"../Pubmed.txt\", \"../Brow Corpus.txt\", repeat=1, max_words_num=4000)\n",
    "ttrs_obj.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrs_obj.visual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure([go.Scatter(x=ttrs_obj.nums1, y=ttrs_obj.ttrs1, name=\"Detail PubMed\"),\n",
    "                         go.Scatter(x=ttrs_obj.nums1, y=[sum(ttrs_obj.ttrs1) / len(ttrs_obj.ttrs1)] * len(ttrs_obj.nums1)\n",
    "                                    , name=\"Average PubMed\"),\n",
    "                         go.Scatter(x=ttrs_obj.nums1, y=ttrs_obj.ttrs2, name=\"Detail BrownCorpus\"),\n",
    "                         go.Scatter(x=ttrs_obj.nums1, y=[sum(ttrs_obj.ttrs2) / len(ttrs_obj.ttrs2)] * len(ttrs_obj.nums1)\n",
    "                                    , name=\"Average BrownCorpus\")])\n",
    "fig.update_layout(xaxis_title=\"随机抽取的单词数目\", yaxis_title=\"Type Token Ratio\",\n",
    "                  title=\"Type Token Ratio 随单词数目变化情况\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class NBClassifier(object):\n",
    "\n",
    "    def __init__(self, X=None, Y=None, feature_size=None):\n",
    "        super(NBClassifier, self).__init__()\n",
    "        if feature_size is None:\n",
    "            raise RuntimeError(\"feature_size is a int type, instead of None\")\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.p_y_1 = 0\n",
    "        self.p_y_0 = 0\n",
    "        self.y_data = []\n",
    "        self.n_data = []\n",
    "        self.x_y = None\n",
    "        self.x_n = None\n",
    "\n",
    "    def fit(self, X=None, Y=None):\n",
    "        if not (X is None):\n",
    "            self.X = X\n",
    "        if not (Y is None):\n",
    "            self.Y = Y\n",
    "        y = 0\n",
    "        n = 0\n",
    "        for item in self.Y:\n",
    "            if item == 1:\n",
    "                y += 1\n",
    "            else:\n",
    "                n += 1\n",
    "        self.p_y_0 = n / len(self.X)\n",
    "        self.p_y_1 = y / len(self.X)\n",
    "        y_data = []\n",
    "        n_data = []\n",
    "        for idx, item in enumerate(self.X):\n",
    "            if self.Y[idx] == 1:\n",
    "                y_data.append(item)\n",
    "            else:\n",
    "                n_data.append(item)\n",
    "        y_data = np.array(y_data)\n",
    "        n_data = np.array(n_data)\n",
    "        self.x_y = y_data.sum(0) / len(y_data)\n",
    "        self.x_n = n_data.sum(0) / len(n_data)\n",
    "\n",
    "    def predict(self, x):\n",
    "        ans1, ans2 = self.prob(x)\n",
    "        ans = np.zeros_like(ans1)\n",
    "        ans[ans1 > ans2] = 1\n",
    "        return ans\n",
    "\n",
    "    def prob(self, x):\n",
    "        if x.ndim != 2:\n",
    "            raise RuntimeError(f\"x's dim is 2, instead of {x.ndim}\")\n",
    "        ans1 = list()\n",
    "        ans2 = list()\n",
    "        for item in x:\n",
    "            prob_y = self.p_y_1\n",
    "            prob_n = self.p_y_0\n",
    "            for idx, val in enumerate(item):\n",
    "                if val == 1:\n",
    "                    prob_y *= self.x_y[idx]\n",
    "                    prob_n *= self.x_n[idx]\n",
    "                else:\n",
    "                    prob_y *= (1 - self.x_y[idx])\n",
    "                    prob_n *= (1 - self.x_n[idx])\n",
    "            ans1.append(prob_y)\n",
    "            ans2.append(prob_n)\n",
    "        ans1, ans2 = np.array(ans1), np.array(ans2)\n",
    "        ans1, ans2 = ans1 / (ans1 + ans2), ans2 / (ans1 + ans2)\n",
    "        return ans1, ans2\n",
    "\n",
    "    def score(self, X, Y):\n",
    "        ans = self.predict(X)\n",
    "        ans = ans - Y\n",
    "        return np.sum(ans == 0) / len(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_real = np.random.randn(100, 10)\n",
    "data_real = np.where(data_real > 0, 1, 0)\n",
    "data_fake = np.random.rand(100, 10)\n",
    "data_fake = np.where(data_fake > 0.8, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nbc = NBClassifier(feature_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack((data_fake, data_real))\n",
    "y = np.hstack((np.zeros(100), np.ones(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbc.fit(data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbc.predict(data_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbc.predict(data_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbc.predict(np.vstack((data_real, data_fake)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbc.score(data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"final set.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.allow_pickle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dufu = data[\"dataset\"].item()[\"dufu\"]\n",
    "sushi = data[\"dataset\"].item()[\"sushi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack((dufu, sushi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ..., 4024, 3507, 4682],\n",
       "       [   0,    0,    0, ..., 1200, 3507, 4682],\n",
       "       [   0,    0,    0, ..., 1834, 3507, 4682],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 3124, 3507, 4682],\n",
       "       [   0,    0,    0, ...,  216, 3507, 4682],\n",
       "       [   0,    0,    0, ..., 4316, 3507, 4682]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.hstack((np.ones(len(dufu)), np.zeros(len(sushi))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = np.zeros((len(data), 4683))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2300, 1210)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, item in enumerate(data):\n",
    "    for i in item:\n",
    "        real_data[idx, i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2300, 4683)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6543478260869565"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KMeans(2)\n",
    "clf.fit(X_train, y_train)\n",
    "(sum(clf.predict(X_test) == y_test)) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7152173913043478"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = naive_bayes.GaussianNB()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7152173913043478"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = naive_bayes.BernoulliNB()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8717391304347826"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = neighbors.KNeighborsClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8108695652173913"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = neighbors.KNeighborsClassifier(2)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8934782608695652"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = NBClassifier(X_train, y_train, 4683)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:64: RuntimeWarning: overflow encountered in double_scalars\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:69: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:48: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5021739130434782"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(real_data, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7304347826086957"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = naive_bayes.GaussianNB()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6543478260869565"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KMeans(2)\n",
    "clf.fit(X_train, y_train)\n",
    "(sum(clf.predict(X_test) == y_test)) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7608695652173914"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = naive_bayes.BernoulliNB()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5108695652173914"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = neighbors.KNeighborsClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9347826086956522"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:69: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:48: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6304347826086957"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = NBClassifier(X_train, y_train, 4683)\n",
    "clf.fit()\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KMeans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3760869565217391"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KMeans(2)\n",
    "clf.fit(X_train, y_train)\n",
    "(sum(clf.predict(X_test) == y_test)) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
